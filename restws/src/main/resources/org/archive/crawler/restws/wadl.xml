<?xml version="1.0" encoding="UTF-8" ?>
<?xml-stylesheet type="text/xsl" href="wadl_documentation.xsl"?>
<application xmlns="http://research.sun.com/wadl/2006/10"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:html="http://www.w3.org/1999/xhtml"
	xsi:schemaLocation="http://research.sun.com/wadl/2006/10 https://wadl.dev.java.net/wadl20061109.xsd
						http://www.w3.org/1999/xhtml http://www.w3.org/2002/08/xhtml/xhtml1-strict.xsd">
	<doc title="Heritrix REST Web Service (draft)">
    <html:p>The REST web service allows you to control a cluster of web crawlers.  It is primarily designed
    with <html:a href="http://crawler.archive.org/">Heritrix 2.0</html:a> in mind but a cluster could
    potentially containing variety of different crawling software as long as it followed this interface.
    This document describes the interface as coherent whole from the clients perspective.  An
    actual server implementation may consist of a gateway module which redirects requests to a crawler-specific service
    running on another host.  This should be basically transparent for client, as long as they follow redirects correctly.</html:p> 
    <html:p>Not all Heritrix functionality is currently available via
    the REST service, you may have to resort to using the JMX API for some
    operations.</html:p>
    <html:p><html:strong>Note:</html:strong> This is a draft, check <html:a href="http://archive-crawler.svn.sourceforge.net/viewvc/*checkout*/archive-crawler/branches/aosborne_restws/restws/src/main/resources/org/archive/crawler/restws/wadl.xml">SVN</html:a>
    for the latest version of this document.  Please email comments to aosborne <html:span>at nla dot</html:span> gov dot au.</html:p>
  </doc>
	<resources base="">
		<resource id="org.archive.crawler.restws.CrawlersResource"
			path="crawlers">
			<method name="GET">
				<doc>List the crawlers available through this service.</doc>
				<request>
					<param style="query" name="version">
						<doc>Filter by crawlers running a particular software version, eg <html:tt>Heritrix 2.0.1</html:tt></doc>
					</param>
				</request>
				<response>
					<representation mediaType="application/atom+xml">
						<doc title="Crawler list">Example:
							<html:pre><html:code>&lt;feed xmlns="http://www.w3.org/2005/Atom" 
      xml:base="http://example.org/crawlers"&gt;
  &lt;id&gt;http://example.org/crawlers&lt;/id&gt;
  &lt;title&gt;Crawlers known to example.org&lt;/title&gt;
  &lt;updated&gt;2008-08-12T13:40:03Z&lt;/updated&gt;
  &lt;author&gt;&lt;name&gt;Heritrix REST-WS 2.0.1&lt;/name&gt;&lt;/author&gt;
  &lt;entry&gt;
    &lt;id&gt;http://example.org/crawlers/c01.example.org:1234:0&lt;/id&gt;
    &lt;title&gt;c01.example.org:1234:0&lt;/title&gt;
    &lt;link rel="alternate" href="c01.example.org:1234:0"/&gt;
    &lt;link rel="jobs" href="c01.example.org:1234:0/jobs" /&gt;
    &lt;link rel="profiles" href="c01.example.org:1234:0/profiles" /&gt;
    &lt;author&gt;&lt;name&gt;Heritrix 2.2.0&lt;/name&gt;&lt;/author&gt;
    &lt;updated&gt;2006-08-12T13:40:03Z&lt;/updated&gt;
    &lt;summary&gt;2 active jobs: awesomejob, someotherjob. Combined rate: 40kb/s. 
    Uptime: 20 minutes.&lt;/summary&gt;
  &lt;/entry&gt;
  &lt;entry&gt;
     ...
  &lt;/entry&gt;
  ...
&lt;/feed&gt;</html:code></html:pre></doc>
					</representation>
					<representation mediaType="text/plain">
						<doc title="Crawler list">Example:<html:pre>http://example.org/crawlers/c01.example.org:1234:0
http://example.org/crawlers/c01.example.org:1234:1
http://example.org/crawlers/c14.example.org:7000:0
...</html:pre></doc>
					</representation>
				</response>
			</method>
			<method name="POST">
				<doc><html:p>Register a remote crawler with the service.</html:p>
				<html:p>Heritrix instances known to the service via JMX will be automatically registered with an id of the form
				<html:em>host</html:em>:<html:em>port</html:em>:<html:em>identifier</html:em>.</html:p></doc>
				<request>
					<representation mediaType="multipart/form-data">
						<doc title="Register crawler request"/>
						<param style="plain" name="id" required="true"><doc>Id of the crawler.  Must be alphanumeric plus dashes and underscores.</doc></param>
						<param style="plain" name="uri" required="true"><doc>URI of the crawler.</doc></param>
					</representation>
				</request>
			</method>
			<resource path="available">
				<method name="POST">
					<doc>Find a crawler that is currently available to take on more jobs.  A reference to the crawler
					will be returned in the Location header.  The returned crawler will locked so that it will
					not be returned in subsequent requests to this action for a short period of time.  This
					gives the consumer of the service a period of exclusive access so that it can create and start a
					job without conflicting with other consumers.</doc>
					<request>
						<param style="query" name="version">
							<doc>Filter by crawlers running a particular software version, eg <html:tt>Heritrix 2.0.1</html:tt></doc>
						</param>
						<param style="query" name="locktime" default="10">
							<doc>Number of seconds the crawler will be locked for.</doc>
						</param>
					</request>
				</method>
			</resource>
			<resource id="org.archive.crawler.restws.CrawlerResource"
				path="{crawler}">
				<param style="template" name="crawler">
					<doc>The id of a crawler.</doc>
				</param>
				<method name="GET">
					<response>
					<!-- TODO: something -->
						<fault status="404">
							<doc title="Unknown crawler">The specified crawler is unknown to the service.</doc>
						</fault>
					</response>
				</method>
	<method name="DELETE">
		<doc>Unregister the crawler from this service.</doc>
	</method>

				<resource id="org.archive.crawler.restws.JobsResource"
					path="jobs">
					<method name="GET">
						<doc>List all crawl jobs.
						
						
						</doc>
						<response>
							<representation mediaType="application/atom+xml">
								<doc title="Job list">Example:
							<html:pre><html:code>&lt;feed xmlns="http://www.w3.org/2005/Atom" 
      xml:base="http://example.org/crawlers/c01.example.org:1234:0/jobs"&gt;
  &lt;id&gt;http://example.org/crawlers/c01.example.org:1234:0/jobs&lt;/id&gt;
  &lt;title&gt;Jobs on c01.example.org&lt;/title&gt;
  &lt;updated&gt;2008-08-12T13:40:03Z&lt;/updated&gt;
  &lt;author&gt;&lt;name&gt;Heritrix 2.0.1&lt;/name&gt;&lt;/author&gt;
  &lt;entry&gt;
    &lt;id&gt;http://example.org/crawlers/c01.example.org:1234:0/jobs/awesomejob&lt;/id&gt;
    &lt;title&gt;awesomejob&lt;/title&gt;
    &lt;link rel="alternate" href="awesomejob"/&gt;
    &lt;link rel="seeds" href="awesomejob/seeds" /&gt;
    &lt;link rel="config" href="awesomejob/config" /&gt;
    &lt;updated&gt;2006-08-12T13:40:03Z&lt;/updated&gt;
    &lt;summary&gt;My awesome job. [20s elapsed. 208 KB received.]&lt;/summary&gt;
  &lt;/entry&gt;
  &lt;entry&gt;
     ...
  &lt;/entry&gt;
  ...
&lt;/feed&gt;</html:code></html:pre></doc></representation>
							<representation mediaType="text/plain">
								<doc title="Job list">Example:<html:pre>http://example.org/crawlers/c01.example.org:1234:0/jobs/awesomejob
http://example.org/crawlers/c01.example.org:1234:0/jobs/anotherjob
http://example.org/crawlers/c01.example.org:1234:0/jobs/someotherjob
...</html:pre></doc>
							</representation>
						</response>
					</method>
	<method name="POST">
		<doc>Create a new job.</doc>
		<request>
			<representation mediaType="multipart/form-data">
				<doc title="Create job request" />
				<param style="plain" name="name" required="true">
					<doc>The name of the new job</doc>
				</param>
				<param style="plain" name="template">
					<doc>The name of an existing job or profile to create this job from.</doc>
				</param>
			</representation>
			<representation mediaType="application/xml">
				<doc title="Create job from specification">
					Creates a new job from a specification.  See the application/xml representation of a
					<html:a href="##JobResource">job</html:a> for details. 
				</doc>
			</representation>
		</request>
		<response>
			<representation status="201">
				<doc title="Job created">
									The job was created successfully.
								</doc>
				<param style="header" name="Location">
					<doc>URL of the created job.</doc>
				</param>
			</representation>
			<fault status="409">
				<doc title="Target already exists">
									A job with the name you specified already exists.  Try a different name.
								</doc>
			</fault>
		</response>
	</method>
					<resource id="org.archive.crawler.restws.JobResource"
						path="{job}">
						<param style="template" name="job">
							<doc>The name of a job.</doc>
						</param>
						<method name="GET">
							<doc>Get information about the job.<html:p>Retrieve an XML or JSON document with the 
							status of the job and crawl statistics.</html:p>
							</doc>
							<response>
								<representation mediaType="application/xml">
									<doc title="Job">
									<html:p>Modeled after the format CDL uses for their Heritrix 1 web service.</html:p>
									<html:p>Example:</html:p>
							<html:pre><html:code><![CDATA[<crawl-job>
  <name>somejob</name>
  <start-time>2008-02-15T20:54:25.857Z</start-time>
  <end-time>2008-02-15T20:54:30.127Z</end-time>
  <status uri="http://example.org/crawlers/c01.example.org:1234:0/jobs/somejob/status">finished</status>
  <read-only>true</read-only>
  <running>false</running>
  <documents-crawled>3</documents-crawled>
  <bytes-downloaded>953</bytes-downloaded>
  <duration>4</duration>
  <documents-per-second>0.75</documents-per-second>
  <kilobytes-per-second>0</kilobytes-per-second>
  <total-hosts-crawled>1</total-hosts-crawled>
  <seed-list uri="http://example.org/crawlers/c01.example.org:1234:0/jobs/somejob/seeds">
    <seed status="crawled">http://gales.cdlib.org/test?key=val&amp;amp;key2=val</seed>
  </seed-list>
  <artifact-list>
    <artifact type="application/arc" uri="http://example.org/crawlers/c01.example.org:1234:0/jobs/somejob/arcs/IAH-20080708013806-00001-c01.example.org.arc.gz"/>
    <artifact type="application/warc" uri="http://example.org/crawlers/c01.example.org:1234:0/jobs/somejob/warcs/IAH-20080708013806-00001-c01.example.org.warc.gz"/>
  </artifact-list>
  <log-list>
    <log name="alerts" uri="http://example.org/crawlers/c01.example.org:1234:0/jobs/somejob/logs/alert.log"/>
    <log name="crawl" uri="http://example.org/crawlers/c01.example.org:1234:0/jobs/somejob/logs/crawl.log"/>
    <log name="progress-statistics" uri="http://example.org/crawlers/c01.example.org:1234:0/jobs/somejob/logs/progress-statistics.log"/>
  </log-list>
  <report-list>
    <report name="hosts" uri="http://example.org/crawlers/c01.example.org:1234:0/jobs/somejob/reports/hosts-report.txt"/>
    <report name="mimetype" uri="http://example.org/crawlers/c01.example.org:1234:0/jobs/somejob/reports/mimetype-report.txt"/>
    <report name="responsecode" uri="http://example.org/crawlers/c01.example.org:1234:0/jobs/somejob/reports/responsecode-report.txt"/>
    <report name="seeds" uri="http://example.org/crawlers/c01.example.org:1234:0/jobs/somejob/reports/seeds-report.txt"/>
    <report name="crawl" uri="http://example.org/crawlers/c01.example.org:1234:0/jobs/somejob/reports/crawl-report.txt"/>
    <report name="processors" uri="http://example.org/crawlers/c01.example.org:1234:0/jobs/somejob/reports/processors-report.txt"/>
    <report name="frontier" uri="http://example.org/crawlers/c01.example.org:1234:0/jobs/somejob/reports/frontier-report.txt"/>
  </report-list>
  <configuration uri="http://example.org/crawlers/c01.example.org:1234:0/jobs/somejob/config">
    <sheet name="global" uri="http://example.org/crawlers/c01.example.org:1234:0/jobs/somejob/config/global">
      ...
    </sheet>
    <sheet name="someoverride" uri="http://example.org/crawlers/c01.example.org:1234:0/jobs/somejob/config/someoverride">
      ...
    </sheet>
  </configuration>
</crawl-job>]]>				  
							</html:code></html:pre>
									</doc>
								</representation>
								<fault status="404">
									<doc title="Job not found">
									The job does not exist or has already been deleted.
								</doc>
								</fault>
							</response>
						</method>
						<method name="DELETE">
							<doc>Delete the job.</doc>
							<response>
								<representation status="204">
									<doc title="Job deleted">
									The job was deleted successfully.
								</doc>
								</representation>
							</response>
						</method>
						<resource id="org.archive.crawler.restws.SeedsResource"
							path="seeds">
							<doc>
							The seed list is the initial set of URLs that crawling will begin from.
						</doc>
							<method name="GET">
								<doc>Get the list of seed URLs.</doc>
								<response>
									<representation status="200" mediaType="text/plain">
										<doc title="Seeds list">
										<html:p>The list of seeds is simply plain text URLs delimited by linefeeds.</html:p>
										<html:p>Example:</html:p>
										<html:pre>http://www.archive.org/
http://www.example.com/
http://example.org/mypage.html</html:pre>
									</doc>
									</representation>
								</response>
							</method>
							<method name="POST">
								<doc>Append some new seed URLs.</doc>
								<request>
									<representation mediaType="text/plain">
										<doc title="Append seeds request">
										The seed URL desired to be appended should be delimited by linefeeds as above and POSTed as text/plain.
									</doc>
									</representation>
								</request>
							</method>
							<method name="PUT">
								<doc>Replace the list of seed URLs.</doc>
								<request>
									<representation mediaType="text/plain">
										<doc title="Replace seeds request">
										The seed list should be delimited by linefeeds as above and PUT as text/plain.
									</doc>
									</representation>
								</request>
							</method>
						</resource>
						<resource id="org.archive.crawler.restws.SheetsResource"
							path="config">
							<doc><html:p>The crawler's confiured is specified via one or more sheets, list of settings that control the crawl. By default, there is only one 
						sheet, the global sheet. The global sheet is consulted when no URL-specific configuration information is needed.
						Other sheets of settings can be created, and these extra sheets can be associated with URLs to provide crawl
						configuration specific to those URLs.</html:p>
							<html:p>Some crawlers may only support the global sheet.</html:p>
						</doc>
							<method name="GET">
								<doc>List the available sheets.</doc>
								<response>
									<representation status="200" mediaType="text/plain"></representation>
									<representation status="200" mediaType="application/xml"></representation>
								</response>
							</method>
							<resource id="org.archive.crawler.restws.SheetResource"
								path="{sheet}">
								<doc><html:p>The actual configuration format is specific to different crawlers and even different versions of crawlers.</html:p>
							<html:p>In Heritrix 2.0, sheets are plain text files that look like this:</html:p>
							<html:pre><html:code>root=map, java.lang.Object
root:metadata=primary, org.archive.modules.writer.DefaultMetadataProvider
root:metadata:robots-honoring-policy=primary, org.archive.modules.net.RobotsHonoringPolicy
root:metadata:robots-honoring-policy:user-agents=list, java.lang.String
root:metadata:description=string, Broad but shallow crawl.
root:loggerModule=primary, org.archive.crawler.framework.CrawlerLoggerModule
[...]</html:code></html:pre>
<html:p>In future versions, beginning with Heritrix 2.2, the configuration system is being redesigned to use Spring XML bean configuration.  
How this will work has not been finalized, but it is likely the REST service will just be able to return chunks of bean XML for each sheet.</html:p>
							</doc>
								<param style="template" name="sheet">
									<doc>The name of a configuration sheet.</doc>
								</param>
								<method name="GET">
									<doc>Get the sheet's configuration.</doc>
								</method>
								<method name="PUT">
									<doc>Set the sheet's configuration.  If the sheet did not previously exist, it will be created.</doc>
								</method>
								<method name="DELETE">
									<doc>Delete the sheet.</doc>
								</method>
								<resource id="org.archive.crawler.restws.SheetSurtsResource"
									path="surts">
									<doc><html:p>Associated with each sheet can be a list of <html:a
										href="http://crawler.archive.org/articles/user_manual/glossary.html#surtprefix">SURT prefixes</html:a>
									which define the URLs the sheet applies to.</html:p></doc>
									<method name="GET">
										<doc>Return the list of SURT prefixes associated with this sheet.</doc>
									</method>
									<method name="POST">
										<doc>Append some new SURT prefixes to this sheet.</doc>
									</method>
									<method name="PUT">
										<doc>Replace the list of SURT prefixes associated with this sheet.</doc>
									</method>
								</resource>
							</resource>
						</resource>
						<resource id="org.archive.crawler.restws.JobStatusResource"
							path="status">
							<doc>The status of the job.  Possible values include:
						<html:ul>
						  <html:li>NASCENT</html:li>
						  <html:li>PREPARING</html:li>
						  <html:li>RUNNING</html:li>
						  <html:li>PAUSING</html:li>
						  <html:li>PAUSED</html:li>
						  <html:li>CHECKPOINTING</html:li>
						  <html:li>STOPPING</html:li>
						  <html:li>FINISHED</html:li>
						  </html:ul>
        				</doc>
							<method name="GET">
								<doc>Get the current status of the job.</doc>
							</method>
							<method name="PUT">
								<doc>
        				<html:p>Change the status of the job.  Only some status transitions are valid, others will return an error.</html:p>
        				<html:p>To launch a NASCENT job, set the status to PREPARING.</html:p>
        				<html:p>To pause a RUNNING or CHECKPOINTING job, set the status to PAUSING.</html:p>
        				<html:p>To resume a PAUSING, PAUSED or CHECKPOINTING job, set the status to RUNNING.</html:p>
        				<html:p>To <html:a
									href="http://crawler.archive.org/articles/user_manual/outside.html#checkpoint">checkpoint</html:a>
        								a RUNNING, PAUSING or PAUSED job, set the status to CHECKPOINTING.</html:p>
        				<html:p>To stop a job with any status, set the status to STOPPING.</html:p>    					
        				</doc>
								<response>
									<fault status="400">
										<doc title="Unknown status">You attempted to assign the job
        						a status which this crawler does not understand.</doc>
									</fault>
									<fault status="409">
										<doc title="Invalid status transition">The job cannot transition
        						directly from its current status to the one you requested.</doc>
									</fault>
								</response>
							</method>
						</resource>
						<resource id="org.archive.crawler.restws.ReportsResource"
							path="reports">
							<doc>Some crawlers provide reports while the crawl is ongoing on more commonly once is has finished.  These
						reports often include statistics about the types of files downloaded.</doc>
							<method name="GET">
								<doc>List the available reports.</doc>
							</method>
							<method name="POST">
								<doc>Trigger report regeneration.  This action may not be supported by all crawlers and if it
							is supported it may be valid only when the job is in a particular state.</doc>
							</method>
							<resource id="org.archive.crawler.restws.ReportResource"
								path="{report}">
								<param style="template" name="report">
									<doc>The filename of a report.</doc>
								</param>
								<method name="GET">
									<doc>Retrieve the contents of the report.</doc>
								</method>
							</resource>
						</resource>
					</resource>
				</resource>
				<resource path="profiles">
					<doc>Profiles act as templates for jobs.  New jobs are created by copying their configuration from an
				existing profile.</doc>
					<method name="GET">
						<doc>List the profiles known to this crawler.</doc>
					</method>
						<method name="POST">
		<doc>Create a new profile.</doc>
		<request>
			<representation mediaType="multipart/form-data">
				<doc title="Create profile request" />
				<param style="plain" name="name" required="true">
					<doc>The name of the new profile</doc>
				</param>
				<param style="plain" name="template">
					<doc>The name of an existing job or profile to create this job from.</doc>
				</param>
			</representation>
		</request>
		<response>
			<representation status="201">
				<doc title="Profile created">
									The profile was created successfully.
								</doc>
				<param style="header" name="Location">
					<doc>URL of the created profile.</doc>
				</param>
			</representation>
			<fault status="409">
				<doc title="Target already exists">
									A profile or job with the name you specified already exists.  Try a different name.
								</doc>
			</fault>
		</response>
	</method>
					<resource path="{profile}">
						<doc>See <html:a href="##org.archive.crawler.restws.JobResource">job</html:a>.</doc>
						<param style="template" name="profile">
							<doc>The name of a profile.</doc>
						</param>
					</resource>
				</resource>
			</resource>
		</resource>
		<resource id="org.archive.crawler.restws.WadlResource" path="/wadl.xml">
			<method name="GET">
				<doc>Return <html:a href="https://wadl.dev.java.net/">WADL</html:a> 
			documentation for the service—an online version of
			this document.  Error messages link to this.</doc>
			</method>
		</resource>
		<resource id="org.archive.crawler.restws.WadlXslResource"
			path="/wadl_documentation.xsl">
			<method name="GET">
				<doc>Return an XSLT stylesheet for styling the WADL documentation as XHTML.
			</doc>
			</method>
		</resource>
	</resources>
</application>