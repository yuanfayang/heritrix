<?xml version="1.0" encoding="ISO-8859-1"?>
<document>
  <properties>
    <title>User Manual</title>
    <author email="stack at archive dot org">St.Ack</author>
    <revision>$Id$</revision>
  </properties>

  <body>
    <section name="User Manual Introduction">
        <p>This manual is targetted at those who just want to run the 
        crawler.  The user has downloaded a Heritrix binary and they need 
        to konw about configuration file formats and how to sourcep and run 
        a crawl.  If you want to build Heritrix from source or if you'd like
        to make contributions and would like to know about contribution 
        conventions, etc., see instead the <a href="developer.html">Developer
        Manual</a>.
        </p>
        </section>

    <section name="Before You Begin">
        <p>See <a href="requirements.html">System Requirements</a>.
        </p>
    </section>

    <section name="For those who have little patience...">
        <p>To run Heritrix, first do the following:
        <source>% export $HERITRIX_HOME=/PATH/TO/BUILT/HERITRIX</source></p>
<p>...where $HERITRIX_HOME is the location of your built Heritrix (i.e.  under
the 'dist' dir if you built w/ Ant, or under the untarred
target/distribution/heritrix.?.?.?.tar.gz dir if you built w/ Maven, or
under the untarred heritrix.?.?.?.tar.gz if you pulled a packaged binary).</p>
                                                                                
<p>Next run:
<source>
    % cd $HERITIRIX_HOME
    % chmod u+x $HERITRIX_HOME/bin/heritrix.sh
    % $HERITRIX_HOME/bin/heritrix --help
</source></p>

<p>This should give you usage output.
</p>

<p>The Usage output will talk of the '&lt;crawl order file>' file.  The 
'&lt;crawl order file>' or 'order.xml' is the "master config file".  It
specifies which modules will be used to  process URIs, in which order URIs will
be processed, how and where files will ge written to disk, how "polite" the
crawler should be, crawl limits, etc.  The configuration system is currently
undergoing revision and the format of order.xml will probably be changed.  The
best thing to do meantime is to copy an existing "order.xml" file.  See under
'docs/example-settings/broad-crawl' for an up-to-date sample configuration that
does a broad crawl (If there is no docs/example-settings in your built
distribution, see crawler.archive.org TODO: Insert url here).
</p>
<p>Before you begin crawling you *MUST* at least change the default user agent
in the order.xml.  You should set this to something meaningful that allows
administrators of sites you'll be crawling to contact you.  Please do not leave
the Archive Open Crawler project's contact information in this field, we do not
have the time or the resources to field complaints about crawlers which we are
not in control of.</p>

<p>Once you have an order.xml file edited to your liking you can run the crawler
by doing the following:
<source>
    $ cd docs/example-settings/broad-crawl
    $ $HERITRIX_HOME/bin/heritrix.sh --no-wui order.xml
</source></p>

<p>You should see output showing the crawler running.  Tail the logs, specified
in your order.xml, to monitor crawler progress.
</p>
<p>You can also control and configure the crawler via the UI.  To start the
crawler w/ the UI enabled run the following:
<source>
    $ $HERITRIX_HOME/bin/heritrix.sh
</source>
</p>
<p>You should see output like the following:
<source>
    14:11:10.415 EVENT  Starting Jetty/4.2.15rc0
    14:11:10.603 EVENT  Checking Resource aliases
    14:11:10.832 EVENT  Started WebApplicationContext[/admin,Admin]
    14:11:11.094 EVENT  Started SocketListener on 0.0.0.0:8080
    14:11:11.095 EVENT  Started org.mortbay.jetty.Server@1f6f0bf
    Heritrix is running
            Web UI on port 8080
</source></p>
<p>Browse to the Web UI to start a crawl and to load and configure crawl jobs.
</p>
    </section>

  <section name="Settings Files">
  <p>The configuration system is currently undergoing extensive revision.
Meantime, refer to the example settings files in the folder that sits under
this doc. at example-settings.  The settings underbroad-crawl are the most 
recent and more likely to work.
</p>

</section>
<section name="Crawling">
<p>TODO
</p>
</section>
<section name="Monitoring the Crawler">
    <p>TODO</p>
</section>

</body>
</document>
