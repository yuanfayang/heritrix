<crawl-order name="example-crawl">
 <comment>
  A simple crawl for example purposes.
 </comment>
 
 <crawler-behavior>

  <http-headers>
   <User-Agent>heritrix-aoc/alpha (+http://crawler.archive.org)</User-Agent>
   <From>archive-crawler-agent@lists.sourceforge.net</From>
  </http-headers>
 
  <selector class="org.archive.crawler.basic.SimpleSelector">
   <seeds src="seeds.txt" />
  </selector>
  
  <scheduler class="org.archive.crawler.basic.SimpleScheduler" />
  
  <store class="org.archive.crawler.basic.SimpleStore" />
 
  <processors>
   <processor 
     name="Preselector" 
     class="org.archive.crawler.basic.SimplePreselector"
     next="Preprocessor">
    <params max-link-depth="0" max-embed-depth="2" />
    <filter
     name="focus"
     class="org.archive.crawler.util.SeedExtensionFilter"
     mode="domain"
     />
   </processor>
   <processor 
     name="Preprocessor" 
     class="org.archive.crawler.basic.SimplePreconditionEnforcer"
     next="DNS">
    <params delay-factor="3" minimum-delay="100" />
   </processor>
   <processor 
     name="DNS" 
     class="org.archive.crawler.basic.FetcherDNS"
     next="HTTP">
   </processor>
   <processor 
     name="HTTP" 
     class="org.archive.crawler.basic.FetcherHTTPSimple"
     next="ExtractorHTTP">
     <params timeout-seconds="10" />
   </processor>
   <processor 
     name="ExtractorHTTP" 
     class="org.archive.crawler.extractor.ExtractorHTTP"
     next="ExtractorHTML">
   </processor>
   <processor 
     name="ExtractorHTML" 
     class="org.archive.crawler.extractor.ExtractorHTML"
   next="ExtractorDOC">
  </processor>
  <processor
  	name="ExtractorDOC"
  	class="org.archive.crawler.extractor.ExtractorDOC"
  	next="ExtractorSWF">
  </processor>
  <processor
    name="ExtractorSWF"
    class="org.archive.crawler.extractor.ExtractorSWF"
    next="ExtractorPDF">
 </processor>
 <processor
   	name="ExtractorPDF"
   	class="org.archive.crawler.extractor.ExtractorPDF"
    next="Archiver">
   </processor>
   <processor 
     name="Archiver" 
     class="org.archive.crawler.basic.ARCWriter"
     next="Updater">
      <compression use="true"/>
	  <arc-files prefix="CRAWL-" max-size-bytes="20000000"/>
   </processor>
   <processor 
     name="Updater" 
     class="org.archive.crawler.basic.CrawlStateUpdater">
   </processor>
  </processors>
 
  <limits>
   <max-toe-threads value="2" />
  </limits>

 </crawler-behavior>
 <disk path="disk" />
 
 <loggers>
  <crawl-statistics>
    <interval>10</interval>
  </crawl-statistics>
</loggers>

</crawl-order>