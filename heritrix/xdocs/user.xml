<?xml version="1.0" encoding="ISO-8859-1"?>
<document>
  <properties>
    <title>User Manual</title>
    <author email="stack at archive dot org">St.Ack</author>
    <revision>$Id$</revision>
  </properties>

  <body>
    <section name="User Manual Introduction">
        <p>This manual is targeted at those who just want to run the 
        crawler.  The user has downloaded a Heritrix binary and they need 
        to know about configuration file formats and how to source and run 
        a crawl.  If you want to build heritrix from source or if you'd like
        to make contributions and would like to know about contribution 
        conventions, etc., see instead the <a href="developer.html">Developer
        Manual</a>.
        </p>
        </section>

    <section name="Before You Begin">
        <p>See <a href="requirements.html">System Requirements</a>.
        </p>
    </section>

    <section name="For those who have little patience...">
        <p>To run Heritrix, first do the following:
        <source>% export $HERITRIX_HOME=/PATH/TO/BUILT/HERITRIX</source></p>
<p>...where <em>$HERITRIX_HOME</em> is the location of your built Heritrix
(i.e.  under the <em>dist</em> dir if you built w/ Ant, or under the untarred
<em>target/distribution/heritrix.?.?.?.tar.gz</em> dir if you built w/ Maven,
or under the untarred 
<em>heritrix.?.?.?.tar.gz</em> if you pulled a packaged binary).</p>
                                                                                
<p>Next run:
<source>
    % cd $HERITRIX_HOME
    % chmod u+x $HERITRIX_HOME/bin/heritrix.sh
    % $HERITRIX_HOME/bin/heritrix --help
</source></p>

<p>This should give you usage output like the following:
<source>Usage: java org.archive.crawler.Heritrix --help|-h
Usage: java org.archive.crawler.Heritrix --no-wui ORDER.XML
Usage: java org.archive.crawler.Heritrix [--port=PORT] \
            [ORDER.XML [--start|--wait|--set]]
Options:
    --help|-h   Prints this message.
    --no-wui    Start crawler without a web User Interface.
    --port      PORT is port the web UI runs on. Default: 8080.
    ORDER.XML   The crawl to launch. Optional if '--no-wui' NOT specified.
    --start     Start crawling using specified ORDER.XML:
    --wait      Load job specified by ORDER.XML but do not start. Default.
    --set       Set specified ORDER.XML as the default.</source>
</p>

<p>The usage output talks of the an <em>ORDER.XML</em> file.  The 
ORDER.XML is the "master config file".  It
specifies which modules will be used to  process URIs, in which order URIs will
be processed, how and where files will ge written to disk, how "polite" the
crawler should be, crawl limits, etc.  The configuration system is currently
undergoing revision and the format of ORDER.XML will probably be changed.  The
best thing to do meantime is to copy an existing <em>order.xml</em>  file.
See under <em>docs/example-settings/broad-crawl</em> for an up-to-date sample
configuration that does a broad crawl (If there is no 
<em>docs/example-settings</em> in your built
distribution, see <a href="http://cvs.sourceforge.net/viewcvs.py/archive-crawler/ArchiveOpenCrawler/xdocs/example-settings/broad-crawl/">crawler.archive.org</a>).
</p>
<p>Before you begin crawling you *MUST* at least change the default 
"User-Agent" and "From" header fields in the order.xml (or via the
administrative interface).  You should set these to something meaningful 
that allows administrators of sites you'll be crawling to contact you.
The software requires that User-Agent value be of the form...</p>

<source>
	  [name] (+[http-url])[optional-etc]
</source>

<p>...where [name] is the crawler identifier and [http-url] is an URL 
giving more information about your crawling efforts. If desired,
additional info may be placed after the close-parenthesis.</p>

<p>Also, the From value must be an email address.</p>
   
<p>(Please do not leave the Archive Open Crawler project's contact 
information in these fields, we do not have the time or the resources to 
field complaints about crawlers which we do not administer.)</p>

<p>Once you have an order.xml file edited to your liking you can run the crawler
by doing the following:
<source>
    $ cd docs/example-settings/broad-crawl
    $ $HERITRIX_HOME/bin/heritrix.sh --no-wui order.xml
</source></p>

<p>You should see output showing the crawler running.  Tail the logs, specified
in your order.xml, to monitor crawler progress.
</p>
<p>You can also control and configure the crawler via the UI.  To start the
crawler w/ the UI enabled run the following:
<source>
    $ $HERITRIX_HOME/bin/heritrix.sh
</source>
</p>
<p>You should see output like the following:
<source>
    14:11:10.415 EVENT  Starting Jetty/4.2.15rc0
    14:11:10.603 EVENT  Checking Resource aliases
    14:11:10.832 EVENT  Started WebApplicationContext[/admin,Admin]
    14:11:11.094 EVENT  Started SocketListener on 0.0.0.0:8080
    14:11:11.095 EVENT  Started org.mortbay.jetty.Server@1f6f0bf
    Heritrix is running
            Web UI on port 8080
</source></p>
<p>Browse to the Web UI to start a crawl and to load and configure crawl jobs.
</p>
    </section>

  <section name="Settings Files">
  <p>The configuration system is currently undergoing extensive revision.
Meantime, refer to the example settings files in the folder that sits under
this doc. at example-settings.  The settings underbroad-crawl are the most 
recent and more likely to work.
</p>

</section>
<section name="Crawling">
<p>TODO
</p>
</section>
<section name="Monitoring the Crawler">
    <p>TODO</p>
</section>
<section name="System Properties">
<p>Below we document system properties passed on the command-line that 
can influence Heritrix behavior.
</p>
<subsection name="heritrix.webapp.path">
<p>Path to webapp directory.  Default: <em>webapps</em>.  Set
to <em>src/webapps</em> if you want to run the webapp inside eclipse, etc.</p>
</subsection>
<subsection name="heritrix.default.orderfile">
<p>Default order.xml file to use when making jobs via the web UI.
Default: <em>webapp/admin/order.xml</em>.
</p>
</subsection>

</section>

</body>
</document>
